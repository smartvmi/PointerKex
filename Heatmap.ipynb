{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7953fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from classes.classes import HeapGraph\n",
    "from utils.file_utils import get_dataset_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "027cb6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_heap(heap_path, json_path):\n",
    "    with open(heap_path, 'rb') as fp:\n",
    "        heap = bytearray(fp.read())\n",
    "\n",
    "    with open(json_path, 'r') as fp:\n",
    "        info = json.load(fp)\n",
    "\n",
    "    # construct graph of openssh' heap\n",
    "    base_addr = info.get('HEAP_START', '00000000')\n",
    "    ssh_struct_addr = str(info.get('SSH_STRUCT_ADDR', None))\n",
    "\n",
    "    if ssh_struct_addr is None or ssh_struct_addr == 'None':\n",
    "        return None, None, None\n",
    "\n",
    "    ssh_struct_addr = ssh_struct_addr.upper()\n",
    "    heap_obj = HeapGraph(heap=heap, base_address=base_addr, ssh_struct_addr=ssh_struct_addr)\n",
    "    heap_obj.create_graph()\n",
    "\n",
    "    return heap_obj.heap_graph, ssh_struct_addr, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f15b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(heap_paths, json_paths, train_subset=True, block_size=100):\n",
    "\n",
    "    limit = len(heap_paths)\n",
    "    if train_subset is True:\n",
    "        limit = min(block_size, limit)\n",
    "\n",
    "    dataset = []\n",
    "    labels = []\n",
    "\n",
    "    total_files_found = 0\n",
    "\n",
    "    for idx in tqdm(range(limit), desc='Data Files'):\n",
    "\n",
    "        # Read the raw heap and json information and create the graph\n",
    "        heap_graph, ssh_struct_addr, info = load_and_clean_heap(heap_path=heap_paths[idx],\n",
    "                                                                json_path=json_paths[idx])\n",
    "\n",
    "        if heap_graph is None:\n",
    "            continue\n",
    "\n",
    "        total_files_found += 1\n",
    "\n",
    "        relevant_nodes = list((info.get('NEWKEYS_1_ADDR').upper(), info.get('NEWKEYS_2_ADDR').upper()))\n",
    "\n",
    "        # Extract state of node(size, number of outgoing edges, parent size, parent outgoing edges, offset)\n",
    "        for node in list(nx.nodes(heap_graph)):\n",
    "            node_info = heap_graph.nodes.get(node)\n",
    "            size = node_info.get('size', 0)\n",
    "            pointer_count = node_info.get('pointer_count', 0)\n",
    "\n",
    "            out_degree = heap_graph.out_degree[node]\n",
    "\n",
    "            # Create the feature vector\n",
    "            # feature_vector = [size, pointer_count, offset, out_degree]\n",
    "            feature_vector = [size, pointer_count, out_degree]\n",
    "            # predecessor_size, predecessor_pointer_count, predecessor_offset, predecessor_out_degree]\n",
    "\n",
    "            dataset.append(feature_vector)\n",
    "            label = 0\n",
    "            if node in relevant_nodes:\n",
    "                label = 1\n",
    "            labels.append(label)\n",
    "\n",
    "    print('Total files found: %d' % total_files_found)\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7487617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all directories for testing\n",
    "test_roots = ['../Smart-VMI/data/validation/scp', '../Smart-VMI/data/validation/OpenSSH',\n",
    "              '../Smart-VMI/data/validation/client-side', '../Smart-VMI/data/validation/port-forwarding']\n",
    "\n",
    "test_sub_directories = []\n",
    "for test_root in test_roots:\n",
    "    sub_dir = os.listdir(test_root)\n",
    "    test_sub_directories = test_sub_directories + [os.path.join(test_root, directory) for directory in sub_dir]\n",
    "test_sub_directories.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be2bff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8596bbbfeae14da8b97ac40646cf903e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Data Files:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files found: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302c3b1b16b54e2895b790453b224744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Data Files:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files found: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552064018bfa47f6804e3d96519fecb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Data Files:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files found: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a1d42393d8480ebf76f6221f972106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Data Files:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files found: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5effa82b86640f2a43dfe1abe8f04f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Data Files:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files found: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319c92de67e243679b7f5121a55e6a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Data Files:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the test dataset for individual scenarios\n",
    "test_data_dict = dict()\n",
    "for inner_idx, test_subdirectory in enumerate(test_sub_directories):\n",
    "    test_heap_paths, test_json_paths = get_dataset_file_paths(test_subdirectory)\n",
    "    test_dataset, test_labels = generate_dataset(heap_paths=test_heap_paths, json_paths=test_json_paths)\n",
    "    test_data_dict[test_subdirectory] = (test_dataset, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559be08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all training directories\n",
    "roots = [\"../Smart-VMI/data/new/scp\", \"../Smart-VMI/data/new/OpenSSH\", \"../Smart-VMI/data/new/client-side\",\n",
    "         \"../Smart-VMI/data/new/port-forwarding\"]\n",
    "sub_directories = []\n",
    "for root in roots:\n",
    "    sub_dir = os.listdir(root)\n",
    "    sub_directories = sub_directories + [os.path.join(root, directory) for directory in sub_dir]\n",
    "sub_directories.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrices for pairwise metrics\n",
    "shape = (len(sub_directories), len(sub_directories))\n",
    "accuracy_matrix = np.zeros(shape=shape)\n",
    "precision_matrix = np.zeros(shape=shape)\n",
    "recall_matrix = np.zeros(shape=shape)\n",
    "f1_score_matrix = np.zeros(shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9317bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each subdirectory and train. Test against all test directories\n",
    "block_size = 100\n",
    "for idx, sub_directory in enumerate(sub_directories):\n",
    "    # Train on one folder, test on others\n",
    "    heap_paths, json_paths = get_dataset_file_paths(sub_directory)\n",
    "    dataset, labels = generate_dataset(heap_paths=heap_paths, json_paths=json_paths, train_subset=False,\n",
    "                                       block_size=block_size)\n",
    "    # If there are no labels, i.e. heaps don't have the NEWKEYS struct in the json file, discard the folder\n",
    "    if len(labels) == 0:\n",
    "        print(sub_directory)\n",
    "        continue\n",
    "        \n",
    "    # Train random forest\n",
    "    clf = RandomForestClassifier(n_estimators=5)\n",
    "    clf.fit(X=dataset, y=labels)\n",
    "\n",
    "    # test across all subdirectories\n",
    "    for inner_idx, test_subdirectory in enumerate(test_sub_directories):\n",
    "        test_dataset, test_labels = test_data_dict.get(test_subdirectory)\n",
    "        if len(test_labels) == 0:\n",
    "            continue\n",
    "        y_pred = clf.predict(test_dataset)\n",
    "        # There are no predicted true positives, then switch to next directory\n",
    "        if np.sum(y_pred) == 0:\n",
    "            continue\n",
    "        precision = precision_score(y_true=test_labels, y_pred=y_pred)\n",
    "        recall = recall_score(y_true=test_labels, y_pred=y_pred)\n",
    "        accuracy = accuracy_score(y_true=test_labels, y_pred=y_pred)\n",
    "        f1 = f1_score(y_true=test_labels, y_pred=y_pred)\n",
    "        accuracy_matrix[idx][inner_idx] = accuracy\n",
    "        precision_matrix[idx][inner_idx] = precision\n",
    "        recall_matrix[idx][inner_idx] = recall\n",
    "        f1_score_matrix[idx][inner_idx] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9256261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = dict()\n",
    "results_dict['accuracy'] = accuracy_matrix\n",
    "results_dict['precision'] = precision_matrix\n",
    "results_dict['recall'] = recall_matrix\n",
    "results_dict['f1_score'] = f1_score_matrix\n",
    "results_dict['train_directories'] = sub_directories\n",
    "results_dict['test_directories'] = test_sub_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ee99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "versions_train = [x.split(sep='/')[-2][0].upper() + '_' + x.split(sep='/')[-1][2:-3] for x in sub_directories[5:]]\n",
    "versions_test = [x.split(sep='/')[-2][0].upper() + '_' + x.split(sep='/')[-1][2:-3] for x in test_sub_directories[5:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e15e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b12622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap and print it\n",
    "# Format of X & Y labels are O_6_8 where O stands for OpenSSH, C for Client-side, P for Port-forwarding and S for SCP.\n",
    "# The next two numbers seperated by '_' denotes which version of OpenSSH was used in that scenario\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(f1_score_matrix[5:, 5:], annot=True, xticklabels=versions_test, yticklabels=versions_train)\n",
    "plt.title(\"Heatmap of training on specific versions only\")\n",
    "plt.xlabel(\"Test Version\")\n",
    "plt.ylabel(\"Train Version\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e828d90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e190d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc8ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(precision_matrix[5:, 5:], annot=True, xticklabels=versions_test, yticklabels=versions_train)\n",
    "plt.title(\"Heatmap of training on specific versions only\")\n",
    "plt.xlabel(\"Test Version\")\n",
    "plt.ylabel(\"Train Version\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c89151",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(recall_matrix[5:, 5:], annot=True, xticklabels=versions_test, yticklabels=versions_train)\n",
    "plt.title(\"Heatmap of training on specific versions only\")\n",
    "plt.xlabel(\"Test Version\")\n",
    "plt.ylabel(\"Train Version\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:student_env] *",
   "language": "python",
   "name": "conda-env-student_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
